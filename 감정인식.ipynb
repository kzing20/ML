{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPLJluMnzHhoh9K6xJSCgL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18b72c55e2d149b98ff2f66f2e0e956b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bda23ff54d704881ad6a6de8130356a0",
              "IPY_MODEL_e9f39c8ce5e743689b68a94bc735feaa",
              "IPY_MODEL_75ef7996e9e143c9a8af39996420a249"
            ],
            "layout": "IPY_MODEL_8a2075f9df0640338caf40758b074463"
          }
        },
        "bda23ff54d704881ad6a6de8130356a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99d9ac172d494116ace408e09a6437c2",
            "placeholder": "​",
            "style": "IPY_MODEL_f8036ebbc5ae432299950b9ac00419b9",
            "value": "Downloading: 100%"
          }
        },
        "e9f39c8ce5e743689b68a94bc735feaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_029f38efcb7c47be81111defe56bc054",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5d3386d1a414b749200a18b481fa941",
            "value": 898823
          }
        },
        "75ef7996e9e143c9a8af39996420a249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dc695cbc700450a89a5d0a8799948f7",
            "placeholder": "​",
            "style": "IPY_MODEL_6cdbfd9a45f645afaa356d3c3e7b1e16",
            "value": " 899k/899k [00:00&lt;00:00, 2.02MB/s]"
          }
        },
        "8a2075f9df0640338caf40758b074463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99d9ac172d494116ace408e09a6437c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8036ebbc5ae432299950b9ac00419b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "029f38efcb7c47be81111defe56bc054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5d3386d1a414b749200a18b481fa941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dc695cbc700450a89a5d0a8799948f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cdbfd9a45f645afaa356d3c3e7b1e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdd1be0f33624bccb867fa6d144b5e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b6fb61461f9447c85a06b885f149a4e",
              "IPY_MODEL_9629010591b44fb8915a4c411a9c387e",
              "IPY_MODEL_7640be2e9bba40bfb178a4900a21f2d7"
            ],
            "layout": "IPY_MODEL_136b6f828b9145899bf92a3e9717fa50"
          }
        },
        "3b6fb61461f9447c85a06b885f149a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_287016d5265f48bdbd9694c35e4455f3",
            "placeholder": "​",
            "style": "IPY_MODEL_32f5eb3378e246cfb5f93923c4475ba8",
            "value": "Downloading: 100%"
          }
        },
        "9629010591b44fb8915a4c411a9c387e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b67cd9090a6248cdafc5e61191e14885",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5293941a91247c2ae0050482ac48bf4",
            "value": 456318
          }
        },
        "7640be2e9bba40bfb178a4900a21f2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f64f2ad8f3e4edc9e45e12462968eb5",
            "placeholder": "​",
            "style": "IPY_MODEL_696af3d7a9cb45949ca84f0d77904629",
            "value": " 456k/456k [00:00&lt;00:00, 659kB/s]"
          }
        },
        "136b6f828b9145899bf92a3e9717fa50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "287016d5265f48bdbd9694c35e4455f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32f5eb3378e246cfb5f93923c4475ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b67cd9090a6248cdafc5e61191e14885": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5293941a91247c2ae0050482ac48bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f64f2ad8f3e4edc9e45e12462968eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "696af3d7a9cb45949ca84f0d77904629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebb9b4aa07b14c2e866f139ea2367f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f71abde378ba494693851e17dd23d5de",
              "IPY_MODEL_63ff714188a648b5b9d0aeaa349bbc1d",
              "IPY_MODEL_ba4f2d3aaf4e4e47999d4b5c5897b458"
            ],
            "layout": "IPY_MODEL_fd5b4c871b8c411abc3e9651fd955aca"
          }
        },
        "f71abde378ba494693851e17dd23d5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49110ad30a5b44728576352c5d00640a",
            "placeholder": "​",
            "style": "IPY_MODEL_f7dffe2fb9fb4ade8a32ed691b861664",
            "value": "Downloading: 100%"
          }
        },
        "63ff714188a648b5b9d0aeaa349bbc1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_703e75134819441e9cf80b3617c4f591",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50603a3e381e471c940e8102156042c1",
            "value": 1355863
          }
        },
        "ba4f2d3aaf4e4e47999d4b5c5897b458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c8d500650014191853337c02511395c",
            "placeholder": "​",
            "style": "IPY_MODEL_d68a238262c249d5931028768d53fb0c",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 2.76MB/s]"
          }
        },
        "fd5b4c871b8c411abc3e9651fd955aca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49110ad30a5b44728576352c5d00640a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7dffe2fb9fb4ade8a32ed691b861664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "703e75134819441e9cf80b3617c4f591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50603a3e381e471c940e8102156042c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c8d500650014191853337c02511395c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d68a238262c249d5931028768d53fb0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12448d94667748d682d5e5dd1fd920c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ad54d9104984cd69965f5bf826350c2",
              "IPY_MODEL_c74215bc326a44039cb62e36e38a5098",
              "IPY_MODEL_f0f575ffc1494c3589ab0311666f6541"
            ],
            "layout": "IPY_MODEL_a66389af5b4c492aa3ffacd936d149b6"
          }
        },
        "9ad54d9104984cd69965f5bf826350c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_154a24a94fd645558a0c2089ff4a3fd9",
            "placeholder": "​",
            "style": "IPY_MODEL_3c68dd1a2d454ed3a261dd991b75f5ce",
            "value": "Downloading: 100%"
          }
        },
        "c74215bc326a44039cb62e36e38a5098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff57b60bd379476d84172d26a2cc9256",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04614474ad7f448e876d760e61a2bf84",
            "value": 481
          }
        },
        "f0f575ffc1494c3589ab0311666f6541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5383d905c874132b9bb4db752b558c7",
            "placeholder": "​",
            "style": "IPY_MODEL_082503cb971f4fd79da989d2f547edaf",
            "value": " 481/481 [00:00&lt;00:00, 18.5kB/s]"
          }
        },
        "a66389af5b4c492aa3ffacd936d149b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "154a24a94fd645558a0c2089ff4a3fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c68dd1a2d454ed3a261dd991b75f5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff57b60bd379476d84172d26a2cc9256": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04614474ad7f448e876d760e61a2bf84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5383d905c874132b9bb4db752b558c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "082503cb971f4fd79da989d2f547edaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2ab9b61767a43839863e62cfb1daf39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11b5afe064dd4699ad5cb51d2ae5644a",
              "IPY_MODEL_98e04bba20f34c6ca28650df82638c5f",
              "IPY_MODEL_0d4dc908269d40cea5896dc154c34a56"
            ],
            "layout": "IPY_MODEL_a55e9b5d687445d1825a93c16d8d28bf"
          }
        },
        "11b5afe064dd4699ad5cb51d2ae5644a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daebb67b510648539825f94031a83bc5",
            "placeholder": "​",
            "style": "IPY_MODEL_532e1b1e07b34137b85399fe455732c0",
            "value": "Downloading: 100%"
          }
        },
        "98e04bba20f34c6ca28650df82638c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cca240bc20b946d8af7f0108939a40d8",
            "max": 501200538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6da7d95a6add4489844c452a3d000d96",
            "value": 501200538
          }
        },
        "0d4dc908269d40cea5896dc154c34a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9347b666a2c2405494ff58077336443d",
            "placeholder": "​",
            "style": "IPY_MODEL_03b2c5eba7ff4cd1b34f18af16ba9d22",
            "value": " 501M/501M [00:07&lt;00:00, 74.0MB/s]"
          }
        },
        "a55e9b5d687445d1825a93c16d8d28bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daebb67b510648539825f94031a83bc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "532e1b1e07b34137b85399fe455732c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cca240bc20b946d8af7f0108939a40d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6da7d95a6add4489844c452a3d000d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9347b666a2c2405494ff58077336443d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03b2c5eba7ff4cd1b34f18af16ba9d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kzing20/ML/blob/main/%EA%B0%90%EC%A0%95%EC%9D%B8%EC%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 라이브러리 설치"
      ],
      "metadata": {
        "id": "Sg1Cm42bGff2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.4.0\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhuLiJu-2Ldq",
        "outputId": "b5d18acb-b13e-4904-ea6c-898da73e128d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.4.0\n",
            "  Downloading transformers-4.4.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.4.0) (2.25.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==4.4.0) (21.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.4.0) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.4.0) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.4.0) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.4.0) (4.64.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers==4.4.0) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.4.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.4.0) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.4.0) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.4.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.4.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.4.0) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=890fda3fa0db56f4938a87a32012084494854c6d24951211d203c9101bd0ba6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=796f561acfb88ea7df9bca2168ef0514c9392cb423ef0f0f7d25317605ddb817\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZpqlIHw8roD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6175de5-45f0-4614-b358-5d0831407745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 19 12:24:28 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    26W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XRVnhxqZGc61",
        "outputId": "75ada561-18d0-410b-af71-976b5bb32c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rGwZdR-NGthb",
        "outputId": "1a18aab2-ad8c-404b-ddfa-cf5cebcb6409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.4.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 다운로드"
      ],
      "metadata": {
        "id": "7VnoTjSBHIMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/declare-lab/MELD.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCgXDJ2MGzXg",
        "outputId": "7505935b-f763-4fa2-daef-7ef3a7b237ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MELD'...\n",
            "remote: Enumerating objects: 487, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 487 (delta 6), reused 0 (delta 0), pack-reused 475\u001b[K\n",
            "Receiving objects: 100% (487/487), 8.12 MiB | 19.51 MiB/s, done.\n",
            "Resolving deltas: 100% (254/254), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "data_path=\"./MELD/data/MELD/*.csv\"\n",
        "data_path_list = glob.glob(data_path)\n",
        "print(data_path_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjl9HjGsHcTX",
        "outputId": "c6e517c6-7365-487f-e20e-ba89386fd0ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['./MELD/data/MELD/train_sent_emo.csv', './MELD/data/MELD/dev_sent_emo.csv', './MELD/data/MELD/test_sent_emo.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 확인"
      ],
      "metadata": {
        "id": "8rD18einI-eJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 './MELD/data/MELD/dev_sent_emo.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO_yz8wyIkmS",
        "outputId": "1a2b9653-ae6a-4137-804a-8b8d0f533a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sr No.,Utterance,Speaker,Emotion,Sentiment,Dialogue_ID,Utterance_ID,Season,Episode,StartTime,EndTime\r\n",
            "1,\"Oh my God, he’s lost it. He’s totally lost it.\",Phoebe,sadness,negative,0,0,4,7,\"00:20:57,256\",\"00:21:00,049\"\r\n",
            "2,What?,Monica,surprise,negative,0,1,4,7,\"00:21:01,927\",\"00:21:03,261\"\r\n",
            "3,\"Or! Or, we could go to the bank, close our accounts and cut them off at the source.\",Ross,neutral,neutral,1,0,4,4,\"00:12:24,660\",\"00:12:30,915\"\r\n",
            "4,You’re a genius!,Chandler,joy,positive,1,1,4,4,\"00:12:32,334\",\"00:12:33,960\"\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 출력\n",
        "import csv\n",
        "for data_path in data_path_list:\n",
        "  f=open(data_path,'r')\n",
        "  rdr = csv.reader(f)\n",
        "\n",
        "  for line in rdr:\n",
        "    print(line)\n",
        "    break\n",
        "\n",
        "  f.close()\n",
        "  break"
      ],
      "metadata": {
        "id": "b8AjJDU1JO8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "058a6aeb-163e-405d-95bf-fe4243bfd45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sr No.', 'Utterance', 'Speaker', 'Emotion', 'Sentiment', 'Dialogue_ID', 'Utterance_ID', 'Season', 'Episode', 'StartTime', 'EndTime']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 세션으로 데이터 분할하기"
      ],
      "metadata": {
        "id": "6WY2c8q5d6gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 저장\n",
        "def split(session):\n",
        "  final_data = []\n",
        "  split_session = []\n",
        "  for line in session:\n",
        "    split_session.append(line)\n",
        "    final_data.append(split_session[:])\n",
        "  return final_data\n",
        "\n",
        "# 유니크한 스피커로 바꾸기\n",
        "def uniq(speaker_set):\n",
        "  if speaker in speaker_set:\n",
        "    uniq_speaker = speaker_set.index(speaker)\n",
        "  else:\n",
        "    speaker_set.append(speaker)\n",
        "    uniq_speaker= speaker_set.index(speaker) \n",
        "  return uniq_speaker\n",
        "\n",
        "for data_path in data_path_list:\n",
        "  f = open(data_path,'r')\n",
        "  rdr = csv.reader(f)\n",
        "\n",
        "  \"\"\" 세션 데이터 저장할 것 \"\"\"\n",
        "  session_dataset = []\n",
        "  session = []\n",
        "  speaker_set =[]\n",
        "\n",
        "  \"\"\" 실제 데이터 저장 방식 \"\"\"\n",
        "  pre_sess = 'start'\n",
        "  for i, line in enumerate(rdr):\n",
        "    if i==0:\n",
        "      \"\"\"저장할 데이터들 index 확인\"\"\"\n",
        "      header = line\n",
        "      utt_idx= header.index('Utterance')\n",
        "      speaker_idx = header.index('Speaker')\n",
        "      emo_idx = header.index('Emotion')\n",
        "      sess_idx = header.index('Dialogue_ID')\n",
        "    else:\n",
        "      utt = line[utt_idx]\n",
        "      speaker = line[speaker_idx]\n",
        "      emotion = line[emo_idx]\n",
        "      sess = line[sess_idx]\n",
        "      if pre_sess == 'start' or sess == pre_sess:\n",
        "        uniq_speaker = uniq(speaker_set)  \n",
        "        session.append([uniq_speaker,utt,emotion])\n",
        "      else:\n",
        "        \"\"\"세션 데이터 저장\"\"\"\n",
        "        session_dataset += split(session)\n",
        "        speaker_set = []\n",
        "        uniq_speaker = uniq(speaker_set)   \n",
        "        session = [[uniq_speaker,utt,emotion]]\n",
        "    \n",
        "      pre_sess = sess\n",
        "\n",
        "  \"\"\"마지막 세션 저장\"\"\"\n",
        "  session_dataset += split(session)\n",
        "  f.close()\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "id": "YVJx4uP6c6kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a= [1,2,3]\n",
        "a = split(a)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8-FYTNGDHk3",
        "outputId": "a1d5b554-7402-4207-d7e2-8b6e0990d7bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1], [1, 2], [1, 2, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3MTXjxodpbM",
        "outputId": "349168d7-ad05-4984-b904-f9aa177184e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkLpK3lVWLF0",
        "outputId": "1d75e220-f2ee-4a02-a27b-33eaf556dbd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0,\n",
              "  'also I was the point person on my company’s transition from the KL-5 to GR-6 system.',\n",
              "  'neutral']]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session_dataset[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDW7BGEoZDoh",
        "outputId": "8d78d7e3-7d20-439b-eca8-a7409f13e9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0,\n",
              "  'also I was the point person on my company’s transition from the KL-5 to GR-6 system.',\n",
              "  'neutral'],\n",
              " [1, 'You must’ve had your hands full.', 'neutral']]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session_dataset[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V3ZWAHhdoe_",
        "outputId": "e4c4193d-9c88-4203-a60a-1bc97ce9a6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0,\n",
              "  'also I was the point person on my company’s transition from the KL-5 to GR-6 system.',\n",
              "  'neutral'],\n",
              " [1, 'You must’ve had your hands full.', 'neutral'],\n",
              " [0, 'That I did. That I did.', 'neutral']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session_dataset[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbYKi_vid5Wi",
        "outputId": "befd72d5-7b4e-4f4b-bdf4-8e20c201eeca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0,\n",
              "  'also I was the point person on my company’s transition from the KL-5 to GR-6 system.',\n",
              "  'neutral'],\n",
              " [1, 'You must’ve had your hands full.', 'neutral'],\n",
              " [0, 'That I did. That I did.', 'neutral'],\n",
              " [1, 'So let’s talk a little bit about your duties.', 'neutral']]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session_dataset[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF9GLoeed9su",
        "outputId": "0e876124-60ff-4671-f4b6-3adf2f3eea2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0,\n",
              "  'also I was the point person on my company’s transition from the KL-5 to GR-6 system.',\n",
              "  'neutral'],\n",
              " [1, 'You must’ve had your hands full.', 'neutral'],\n",
              " [0, 'That I did. That I did.', 'neutral'],\n",
              " [1, 'So let’s talk a little bit about your duties.', 'neutral'],\n",
              " [0, 'My duties?  All right.', 'surprise']]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session_dataset[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ0JJv3ueKBB",
        "outputId": "8c25318f-aa45-4a93-fece-522ffbb83369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0,\n",
              "  'also I was the point person on my company’s transition from the KL-5 to GR-6 system.',\n",
              "  'neutral'],\n",
              " [1, 'You must’ve had your hands full.', 'neutral'],\n",
              " [0, 'That I did. That I did.', 'neutral'],\n",
              " [1, 'So let’s talk a little bit about your duties.', 'neutral'],\n",
              " [0, 'My duties?  All right.', 'surprise'],\n",
              " [1,\n",
              "  'Now you’ll be heading a whole division, so you’ll have a lot of duties.',\n",
              "  'neutral'],\n",
              " [0, 'I see.', 'neutral'],\n",
              " [1,\n",
              "  'But there’ll be perhaps 30 people under you so you can dump a certain amount on them.',\n",
              "  'neutral'],\n",
              " [0, 'Good to know.', 'neutral'],\n",
              " [1, 'We can go into detail', 'neutral'],\n",
              " [0, 'No don’t I beg of you!', 'fear']]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session_dataset[28]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfP9cwhceVvu",
        "outputId": "ea0f5d54-8189-4912-932a-11d9da55febe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 'Hey, Mon.', 'neutral'],\n",
              " [1, 'Hey-hey-hey. You wanna hear something that sucks.', 'neutral'],\n",
              " [0, 'Do I ever.', 'joy'],\n",
              " [1, 'Chris says they’re closing down the bar.', 'sadness'],\n",
              " [0, 'No way!', 'surprise'],\n",
              " [1,\n",
              "  'Yeah, apparently they’re turning it into some kinda coffee place.',\n",
              "  'neutral'],\n",
              " [0, 'Just coffee! Where are we gonna hang out now?', 'disgust'],\n",
              " [1, 'Got me.', 'sadness']]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실제 감정인식에 맞게 데이터 분할하기 (배치처리 알아보기)"
      ],
      "metadata": {
        "id": "8LXu8qBd-jfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from torch.utils.data import Dataset\n",
        "def split(session):\n",
        "    final_data = []\n",
        "    split_session = []\n",
        "    for line in session:\n",
        "        split_session.append(line)\n",
        "        final_data.append(split_session[:])    \n",
        "    return final_data\n",
        "\n",
        "class data_loader(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        f = open(data_path, 'r')\n",
        "        rdr = csv.reader(f)\n",
        "        \n",
        "        \"\"\" 추가 \"\"\"\n",
        "        emoSet = set()\n",
        "\n",
        "        \"\"\" 세션 데이터 저장할 것\"\"\"\n",
        "        self.session_dataset = []\n",
        "        session = []\n",
        "        speaker_set = []\n",
        "\n",
        "        \"\"\" 실제 데이터 저장 방식 \"\"\"\n",
        "        pre_sess = 'start'\n",
        "        for i, line in enumerate(rdr):\n",
        "            if i == 0:\n",
        "                \"\"\" 저장할 데이터들 index 확인 \"\"\"\n",
        "                header  = line\n",
        "                utt_idx = header.index('Utterance')\n",
        "                speaker_idx = header.index('Speaker')\n",
        "                emo_idx = header.index('Emotion')\n",
        "                sess_idx = header.index('Dialogue_ID')\n",
        "            else:\n",
        "                utt = line[utt_idx]\n",
        "                speaker = line[speaker_idx]\n",
        "                \"\"\" 유니크한 스피커로 바꾸기 \"\"\"\n",
        "                if speaker in speaker_set:\n",
        "                    uniq_speaker = speaker_set.index(speaker)\n",
        "                else:\n",
        "                    speaker_set.append(speaker)\n",
        "                    uniq_speaker = speaker_set.index(speaker)\n",
        "                emotion = line[emo_idx]\n",
        "                sess = line[sess_idx]\n",
        "\n",
        "                if pre_sess == 'start' or sess == pre_sess:\n",
        "                    session.append([uniq_speaker, utt, emotion])\n",
        "                else:\n",
        "                    \"\"\" 세션 데이터 저장 \"\"\"\n",
        "                    self.session_dataset += split(session)\n",
        "                    session = [[uniq_speaker, utt, emotion]]\n",
        "                    speaker_set = []\n",
        "                    emoSet.add(emotion)\n",
        "                pre_sess = sess   \n",
        "        \"\"\" 마지막 세션 저장 \"\"\"\n",
        "        self.session_dataset += split(session)\n",
        "            \n",
        "        \"\"\" 추가 \"\"\"\n",
        "        # self.emoList = sorted(emoSet) # 항상 같은 레이블 순서를 유지하기 위해\n",
        "        self.emoList = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n",
        "        f.close()\n",
        "        \n",
        "    def __len__(self): # 기본적인 구성\n",
        "        return len(self.session_dataset)\n",
        "    \n",
        "    def __getitem__(self, idx): # 기본적인 구성\n",
        "        return self.session_dataset[idx]\n",
        "    \n",
        "    def collate_fn(self, sessions): # 배치를 위한 구성\n",
        "        '''\n",
        "            input:\n",
        "                data: [(session1), (session2), ... ]\n",
        "            return:\n",
        "                batch_input_tokens_pad: (B, L) padded\n",
        "                batch_labels: (B)\n",
        "        '''\n",
        "        batch_input_token = []\n",
        "        for session in sessions:\n",
        "            input_token = \"\"\n",
        "            for line in session:\n",
        "                speaker, utt, emotion = line\n",
        "                input_token += utt\n",
        "            batch_input_token.append(input_token)\n",
        "        \n",
        "        return batch_input_token"
      ],
      "metadata": {
        "id": "q_ya7I-fii2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_dataset = data_loader('./MELD/data/MELD/dev_sent_emo.csv')\n",
        "dev_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G_sG57k-kYE",
        "outputId": "a6015af2-77da-4f5e-d830-3de0146e6bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 'Oh my God, he’s lost it. He’s totally lost it.', 'sadness']]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_dataset[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykfdk63L-w2G",
        "outputId": "a556214d-0da2-47b9-c98e-7f0a30171b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 'Oh my God, he’s lost it. He’s totally lost it.', 'sadness'],\n",
              " [1, 'What?', 'surprise']]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" 배치 결과 확인 \"\"\"\n",
        "from torch.utils.data import DataLoader\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=1, shuffle=False, num_workers=4, collate_fn=dev_dataset.collate_fn)\n",
        "\n",
        "i = 0\n",
        "for data in dev_dataloader:\n",
        "    print(i, data)\n",
        "    i += 1\n",
        "    if i > 2:\n",
        "        break    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsIikrBj-2fy",
        "outputId": "f5233932-50fb-4d29-bee7-9766cd021ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 ['Oh my God, he’s lost it. He’s totally lost it.']\n",
            "1 ['Oh my God, he’s lost it. He’s totally lost it.What?']\n",
            "2 ['Or! Or, we could go to the bank, close our accounts and cut them off at the source.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" 배치 결과 확인 \"\"\"\n",
        "from torch.utils.data import DataLoader\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=3, shuffle=False, num_workers=4, collate_fn=dev_dataset.collate_fn)\n",
        "i = 0\n",
        "for data in dev_dataloader:\n",
        "    print(i,data)\n",
        "    i += 1\n",
        "    if i > 2:\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G4aTyj4ADSH",
        "outputId": "ad2dbef1-24f7-4098-e802-9d748f22f556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 ['Oh my God, he’s lost it. He’s totally lost it.', 'Oh my God, he’s lost it. He’s totally lost it.What?', 'Or! Or, we could go to the bank, close our accounts and cut them off at the source.']\n",
            "1 ['Or! Or, we could go to the bank, close our accounts and cut them off at the source.You’re a genius!', 'Or! Or, we could go to the bank, close our accounts and cut them off at the source.You’re a genius!Aww, man, now we won’t be bank buddies!', 'Or! Or, we could go to the bank, close our accounts and cut them off at the source.You’re a genius!Aww, man, now we won’t be bank buddies!Now, there’s two reasons.']\n",
            "2 ['Or! Or, we could go to the bank, close our accounts and cut them off at the source.You’re a genius!Aww, man, now we won’t be bank buddies!Now, there’s two reasons.Hey.', 'Or! Or, we could go to the bank, close our accounts and cut them off at the source.You’re a genius!Aww, man, now we won’t be bank buddies!Now, there’s two reasons.Hey.Hey!', 'Or! Or, we could go to the bank, close our accounts and cut them off at the source.You’re a genius!Aww, man, now we won’t be bank buddies!Now, there’s two reasons.Hey.Hey!Ohh, you guys, remember that cute client I told you about? I bit him.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 사전 학습 모델들에 대한 백그라운드"
      ],
      "metadata": {
        "id": "8kFNpN7OBAgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" 토크나이저 확인하기 \"\"\"\n",
        "# https://github.com/thunlp/PLMpapers\n",
        "from transformers import RobertaTokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197,
          "referenced_widgets": [
            "18b72c55e2d149b98ff2f66f2e0e956b",
            "bda23ff54d704881ad6a6de8130356a0",
            "e9f39c8ce5e743689b68a94bc735feaa",
            "75ef7996e9e143c9a8af39996420a249",
            "8a2075f9df0640338caf40758b074463",
            "99d9ac172d494116ace408e09a6437c2",
            "f8036ebbc5ae432299950b9ac00419b9",
            "029f38efcb7c47be81111defe56bc054",
            "a5d3386d1a414b749200a18b481fa941",
            "7dc695cbc700450a89a5d0a8799948f7",
            "6cdbfd9a45f645afaa356d3c3e7b1e16",
            "fdd1be0f33624bccb867fa6d144b5e4c",
            "3b6fb61461f9447c85a06b885f149a4e",
            "9629010591b44fb8915a4c411a9c387e",
            "7640be2e9bba40bfb178a4900a21f2d7",
            "136b6f828b9145899bf92a3e9717fa50",
            "287016d5265f48bdbd9694c35e4455f3",
            "32f5eb3378e246cfb5f93923c4475ba8",
            "b67cd9090a6248cdafc5e61191e14885",
            "e5293941a91247c2ae0050482ac48bf4",
            "5f64f2ad8f3e4edc9e45e12462968eb5",
            "696af3d7a9cb45949ca84f0d77904629",
            "ebb9b4aa07b14c2e866f139ea2367f93",
            "f71abde378ba494693851e17dd23d5de",
            "63ff714188a648b5b9d0aeaa349bbc1d",
            "ba4f2d3aaf4e4e47999d4b5c5897b458",
            "fd5b4c871b8c411abc3e9651fd955aca",
            "49110ad30a5b44728576352c5d00640a",
            "f7dffe2fb9fb4ade8a32ed691b861664",
            "703e75134819441e9cf80b3617c4f591",
            "50603a3e381e471c940e8102156042c1",
            "8c8d500650014191853337c02511395c",
            "d68a238262c249d5931028768d53fb0c"
          ]
        },
        "id": "Mi_0OdtYAGcD",
        "outputId": "bbaff5a4-58e0-4452-f699-d592551e49ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18b72c55e2d149b98ff2f66f2e0e956b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdd1be0f33624bccb867fa6d144b5e4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebb9b4aa07b14c2e866f139ea2367f93"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token)\n",
        "print(tokenizer.cls_token_id, tokenizer.sep_token_id, tokenizer.pad_token_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcKFS3nwI5IH",
        "outputId": "cd1d5ee8-06e4-42fe-9b71-4594dfa58d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> </s> <pad>\n",
            "0 2 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dir(tokenizer)\n",
        "tokenizer.model_max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61k89ZAYJACj",
        "outputId": "fd342661-b052-4322-91be-f92171816b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" 토크나이저 작동 \"\"\"\n",
        "res = tokenizer('hello. this is fastcampus')\n",
        "print(res)\n",
        "res = tokenizer.encode('hello. this is fastcampus')\n",
        "print(res)\n",
        "res = tokenizer(['hello. this is fastcampus', \"what are you doing?\"])\n",
        "print(res)\n",
        "res = tokenizer(['hello. this is fastcampus', \"what are you doing?\"], add_special_tokens=False)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udZFPgqSJDTn",
        "outputId": "a3ae3727-f77d-4476-810c-3d016f3def21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [0, 42891, 4, 42, 16, 1769, 28135, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "[0, 42891, 4, 42, 16, 1769, 28135, 2]\n",
            "{'input_ids': [[0, 42891, 4, 42, 16, 1769, 28135, 2], [0, 12196, 32, 47, 608, 116, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}\n",
            "{'input_ids': [[42891, 4, 42, 16, 1769, 28135], [12196, 32, 47, 608, 116]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" 배치 입력 토큰들 처리 \"\"\"\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import RobertaTokenizer\n",
        "import csv\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "def split(session):\n",
        "    final_data = []\n",
        "    split_session = []\n",
        "    for line in session:\n",
        "        split_session.append(line)\n",
        "        final_data.append(split_session[:])    \n",
        "    return final_data\n",
        "\n",
        "class data_loader(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        f = open(data_path, 'r')\n",
        "        rdr = csv.reader(f)\n",
        "        \n",
        "        \"\"\" 추가 \"\"\"\n",
        "        emoSet = set()\n",
        "        self.tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "        \"\"\" 세션 데이터 저장할 것\"\"\"\n",
        "        self.session_dataset = []\n",
        "        session = []\n",
        "        speaker_set = []\n",
        "\n",
        "        \"\"\" 실제 데이터 저장 방식 \"\"\"\n",
        "        pre_sess = 'start'\n",
        "        for i, line in enumerate(rdr):\n",
        "            if i == 0:\n",
        "                \"\"\" 저장할 데이터들 index 확인 \"\"\"\n",
        "                header  = line\n",
        "                utt_idx = header.index('Utterance')\n",
        "                speaker_idx = header.index('Speaker')\n",
        "                emo_idx = header.index('Emotion')\n",
        "                sess_idx = header.index('Dialogue_ID')\n",
        "            else:\n",
        "                utt = line[utt_idx]\n",
        "                speaker = line[speaker_idx]\n",
        "                \"\"\" 유니크한 스피커로 바꾸기 \"\"\"\n",
        "                if speaker in speaker_set:\n",
        "                    uniq_speaker = speaker_set.index(speaker)\n",
        "                else:\n",
        "                    speaker_set.append(speaker)\n",
        "                    uniq_speaker = speaker_set.index(speaker)\n",
        "                emotion = line[emo_idx]\n",
        "                sess = line[sess_idx]\n",
        "\n",
        "                if pre_sess == 'start' or sess == pre_sess:\n",
        "                    session.append([uniq_speaker, utt, emotion])\n",
        "                else:\n",
        "                    \"\"\" 세션 데이터 저장 \"\"\"\n",
        "                    self.session_dataset += split(session)\n",
        "                    session = [[uniq_speaker, utt, emotion]]\n",
        "                    speaker_set = []\n",
        "                    emoSet.add(emotion)\n",
        "                pre_sess = sess   \n",
        "        \"\"\" 마지막 세션 저장 \"\"\"\n",
        "        self.session_dataset += split(session)\n",
        "            \n",
        "        # self.emoList = sorted(emoSet) # 항상 같은 레이블 순서를 유지하기 위해\n",
        "        self.emoList = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n",
        "        f.close()\n",
        "        \n",
        "    def __len__(self): # 기본적인 구성\n",
        "        return len(self.session_dataset)\n",
        "    \n",
        "    def __getitem__(self, idx): # 기본적인 구성\n",
        "        return self.session_dataset[idx]\n",
        "    \n",
        "    def padding(self, batch_input_token):\n",
        "        \"\"\" 추가 \"\"\"\n",
        "        \"\"\" 512 토큰 길이 넘으면 잘라내기 \"\"\"\n",
        "        batch_token_ids, batch_attention_masks = batch_input_token['input_ids'], batch_input_token['attention_mask']\n",
        "        trunc_batch_token_ids, trunc_batch_attention_masks = [], []\n",
        "        for batch_token_id, batch_attention_mask in zip(batch_token_ids, batch_attention_masks):\n",
        "            if len(batch_token_id) > self.tokenizer.model_max_length:\n",
        "                trunc_batch_token_id = [batch_token_id[0]] + batch_token_id[1:][-self.tokenizer.model_max_length+1:]\n",
        "                trunc_batch_attention_mask = [batch_attention_mask[0]] + batch_attention_mask[1:][-self.tokenizer.model_max_length+1:]\n",
        "                trunc_batch_token_ids.append(trunc_batch_token_id)\n",
        "                trunc_batch_attention_masks.append(trunc_batch_attention_mask)\n",
        "            else:\n",
        "                trunc_batch_token_ids.append(batch_token_id)\n",
        "                trunc_batch_attention_masks.append(batch_attention_mask)\n",
        "        \n",
        "        \"\"\" padding token으로 패딩하기 \"\"\"\n",
        "        # [10, 30, 50]\n",
        "        # [50, 50, 50] \n",
        "        # 50-10=40 , 50-30=20 : 패딩토큰으로 채운다. <pad>\n",
        "        max_length = max([len(x) for x in trunc_batch_token_ids])\n",
        "        padding_tokens, padding_attention_masks = [], []\n",
        "        for batch_token_id, batch_attention_mask in zip(trunc_batch_token_ids, trunc_batch_attention_masks):\n",
        "            padding_tokens.append(batch_token_id + [self.tokenizer.pad_token_id for _ in range(max_length-len(batch_token_id))])\n",
        "            padding_attention_masks.append(batch_attention_mask + [0 for _ in range(max_length-len(batch_token_id))]                                                        )\n",
        "        return torch.tensor(padding_tokens), torch.tensor(padding_attention_masks)\n",
        "    \n",
        "    def collate_fn(self, sessions): # 배치를 위한 구성\n",
        "        '''\n",
        "            input:\n",
        "                data: [(session1), (session2), ... ]\n",
        "            return:\n",
        "                batch_input_tokens_pad: (B, L) padded\n",
        "                batch_labels: (B)\n",
        "        '''\n",
        "        ## [발화1, 발화2, ..., 발화8]\n",
        "        # 발화1~발화7 컨텍스트로 사용한다면 입력이 길어진다.\n",
        "        # 발화1 같은 경우는 발화8에 덜중요할거에요.\n",
        "        # 적절하게 컨텍스트 길이를 조절해도된다.\n",
        "        # 3개로 정한다면, [발화5,발화6,발화7,발화8]\n",
        "        \"\"\" 추가 \"\"\"\n",
        "        batch_input, batch_labels = [], []\n",
        "        batch_PM_input = []\n",
        "        for session in sessions:\n",
        "            input_str = self.tokenizer.cls_token\n",
        "            \n",
        "            \"\"\" For PM \"\"\"\n",
        "            current_speaker, current_utt, current_emotion = session[-1]\n",
        "            PM_input = []\n",
        "            for i, line in enumerate(session):\n",
        "                speaker, utt, emotion = line\n",
        "                input_str += \" \" + utt + self.tokenizer.sep_token\n",
        "                if i < len(session)-1 and current_speaker == speaker:\n",
        "                    PM_input.append(self.tokenizer.encode(utt, add_special_tokens=True, return_tensors='pt'))\n",
        "                    # [cls_token, tokens, sep_token]\n",
        "                    \n",
        "            \"\"\" For CoM \"\"\"\n",
        "            batch_input.append(input_str)\n",
        "            batch_labels.append(self.emoList.index(emotion))\n",
        "            batch_PM_input.append(PM_input)\n",
        "        batch_input_token = self.tokenizer(batch_input, add_special_tokens=False)\n",
        "        batch_padding_token, batch_padding_attention_mask = self.padding(batch_input_token)\n",
        "        \n",
        "        return batch_padding_token, batch_padding_attention_mask, batch_PM_input, torch.tensor(batch_labels)"
      ],
      "metadata": {
        "id": "fVfsokpBJOs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" 배치 결과 확인 \"\"\"\n",
        "from torch.utils.data import DataLoader\n",
        "dev_dataset = data_loader('./MELD/data/MELD/dev_sent_emo.csv')\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=3, shuffle=False, num_workers=4, collate_fn=dev_dataset.collate_fn)\n",
        "\n",
        "for i, data in enumerate(dev_dataloader):\n",
        "    if i == 1:\n",
        "        print(i,data[0].shape)\n",
        "        batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n",
        "        print(\"batch_padding_token\", batch_padding_token)\n",
        "        print(\"batch_padding_attention_mask\", batch_padding_attention_mask)\n",
        "        print(\"batch_PM_input\", batch_PM_input)\n",
        "        print(\"batch_label\", batch_label)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhJxKSP0XL4M",
        "outputId": "6d7ddfed-d6df-49a6-aa6d-bb589f918a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 torch.Size([3, 58])\n",
            "batch_padding_token tensor([[    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n",
            "           827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n",
            "             5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n",
            "           328,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n",
            "           827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n",
            "             5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n",
            "           328,     2,    83, 33130,     6,   313,     6,   122,    52,   351,\n",
            "            17,    27,    90,    28,   827, 30489,   328,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n",
            "           827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n",
            "             5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n",
            "           328,     2,    83, 33130,     6,   313,     6,   122,    52,   351,\n",
            "            17,    27,    90,    28,   827, 30489,   328,     2,   978,     6,\n",
            "            89,    17,    27,    29,    80,  2188,     4,     2]])\n",
            "batch_padding_attention_mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "batch_PM_input [[], [], [tensor([[    0,  1185,    17,    27,   241,    10, 16333,   328,     2]])]]\n",
            "batch_label tensor([3, 5, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 파일로 저장하기"
      ],
      "metadata": {
        "id": "ftYmyr1Re-HW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!touch dataset.py\n",
        "# 코드 복사하기"
      ],
      "metadata": {
        "id": "OVXtB3mRcr0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import data_loader\n",
        "from torch.utils.data import DataLoader\n",
        "dev_dataset = data_loader('./MELD/data/MELD/dev_sent_emo.csv')\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=3, shuffle=False, num_workers=4, collate_fn=dev_dataset.collate_fn)\n",
        "\n",
        "for i, data in enumerate(dev_dataloader):\n",
        "    if i == 1:\n",
        "        print(data[0].shape)\n",
        "        batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n",
        "        print(\"batch_padding_token\", batch_padding_token)\n",
        "        print(\"batch_padding_attention_mask\", batch_padding_attention_mask)\n",
        "        print(\"batch_PM_input\", batch_PM_input)\n",
        "        print(\"batch_label\", batch_label)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "2jK4iy1IMh_O",
        "outputId": "608832aa-ae11-4c9e-bcfe-9c2b1e05a919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-c28220f78c4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdev_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./MELD/data/MELD/dev_sent_emo.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdev_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'data_loader' from 'dataset' (/content/dataset.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **사전학습 모델 불러와서 로딩하기**"
      ],
      "metadata": {
        "id": "o26qvv1eMvXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaModel\n",
        "model = RobertaModel.from_pretrained('roberta-base')\n",
        "print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127,
          "referenced_widgets": [
            "12448d94667748d682d5e5dd1fd920c6",
            "9ad54d9104984cd69965f5bf826350c2",
            "c74215bc326a44039cb62e36e38a5098",
            "f0f575ffc1494c3589ab0311666f6541",
            "a66389af5b4c492aa3ffacd936d149b6",
            "154a24a94fd645558a0c2089ff4a3fd9",
            "3c68dd1a2d454ed3a261dd991b75f5ce",
            "ff57b60bd379476d84172d26a2cc9256",
            "04614474ad7f448e876d760e61a2bf84",
            "f5383d905c874132b9bb4db752b558c7",
            "082503cb971f4fd79da989d2f547edaf",
            "f2ab9b61767a43839863e62cfb1daf39",
            "11b5afe064dd4699ad5cb51d2ae5644a",
            "98e04bba20f34c6ca28650df82638c5f",
            "0d4dc908269d40cea5896dc154c34a56",
            "a55e9b5d687445d1825a93c16d8d28bf",
            "daebb67b510648539825f94031a83bc5",
            "532e1b1e07b34137b85399fe455732c0",
            "cca240bc20b946d8af7f0108939a40d8",
            "6da7d95a6add4489844c452a3d000d96",
            "9347b666a2c2405494ff58077336443d",
            "03b2c5eba7ff4cd1b34f18af16ba9d22"
          ]
        },
        "id": "5AvVbv5KfG9v",
        "outputId": "f3dcd809-91e4-4fdc-d07a-80dd9b331a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12448d94667748d682d5e5dd1fd920c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2ab9b61767a43839863e62cfb1daf39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "dir(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1sQFqRXHtla",
        "outputId": "7e993182-5cfa-4512-b5c7-45aed328991b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T_destination',\n",
              " '__annotations__',\n",
              " '__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattr__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_apply',\n",
              " '_backward_hooks',\n",
              " '_buffers',\n",
              " '_call_impl',\n",
              " '_convert_head_mask_to_5d',\n",
              " '_expand_inputs_for_generation',\n",
              " '_forward_hooks',\n",
              " '_forward_pre_hooks',\n",
              " '_get_backward_hooks',\n",
              " '_get_decoder_start_token_id',\n",
              " '_get_logits_processor',\n",
              " '_get_logits_warper',\n",
              " '_get_name',\n",
              " '_get_pad_token_id',\n",
              " '_get_resized_embeddings',\n",
              " '_get_resized_lm_head',\n",
              " '_get_stopping_criteria',\n",
              " '_hook_rss_memory_post_forward',\n",
              " '_hook_rss_memory_pre_forward',\n",
              " '_init_sequence_length_for_generation',\n",
              " '_init_weights',\n",
              " '_is_full_backward_hook',\n",
              " '_keys_to_ignore_on_load_missing',\n",
              " '_keys_to_ignore_on_load_unexpected',\n",
              " '_keys_to_ignore_on_save',\n",
              " '_load_from_state_dict',\n",
              " '_load_state_dict_post_hooks',\n",
              " '_load_state_dict_pre_hooks',\n",
              " '_maybe_warn_non_full_backward_hook',\n",
              " '_modules',\n",
              " '_named_members',\n",
              " '_non_persistent_buffers_set',\n",
              " '_parameters',\n",
              " '_prepare_attention_mask_for_generation',\n",
              " '_prepare_decoder_input_ids_for_generation',\n",
              " '_prepare_encoder_decoder_kwargs_for_generation',\n",
              " '_prepare_input_ids_for_generation',\n",
              " '_prune_heads',\n",
              " '_register_load_state_dict_pre_hook',\n",
              " '_register_state_dict_hook',\n",
              " '_reorder_cache',\n",
              " '_replicate_for_data_parallel',\n",
              " '_resize_token_embeddings',\n",
              " '_save_to_state_dict',\n",
              " '_slow_forward',\n",
              " '_state_dict_hooks',\n",
              " '_tie_encoder_decoder_weights',\n",
              " '_tie_or_clone_weights',\n",
              " '_update_model_kwargs_for_generation',\n",
              " '_update_seq_length_for_generation',\n",
              " '_version',\n",
              " 'add_memory_hooks',\n",
              " 'add_module',\n",
              " 'adjust_logits_during_generation',\n",
              " 'apply',\n",
              " 'base_model',\n",
              " 'base_model_prefix',\n",
              " 'beam_sample',\n",
              " 'beam_search',\n",
              " 'bfloat16',\n",
              " 'buffers',\n",
              " 'children',\n",
              " 'config',\n",
              " 'config_class',\n",
              " 'cpu',\n",
              " 'cuda',\n",
              " 'device',\n",
              " 'double',\n",
              " 'dtype',\n",
              " 'dummy_inputs',\n",
              " 'dump_patches',\n",
              " 'embeddings',\n",
              " 'encoder',\n",
              " 'estimate_tokens',\n",
              " 'eval',\n",
              " 'extra_repr',\n",
              " 'float',\n",
              " 'floating_point_ops',\n",
              " 'forward',\n",
              " 'from_pretrained',\n",
              " 'generate',\n",
              " 'get_buffer',\n",
              " 'get_extended_attention_mask',\n",
              " 'get_extra_state',\n",
              " 'get_head_mask',\n",
              " 'get_input_embeddings',\n",
              " 'get_output_embeddings',\n",
              " 'get_parameter',\n",
              " 'get_submodule',\n",
              " 'greedy_search',\n",
              " 'group_beam_search',\n",
              " 'half',\n",
              " 'init_weights',\n",
              " 'invert_attention_mask',\n",
              " 'ipu',\n",
              " 'is_parallelizable',\n",
              " 'load_state_dict',\n",
              " 'modules',\n",
              " 'name_or_path',\n",
              " 'named_buffers',\n",
              " 'named_children',\n",
              " 'named_modules',\n",
              " 'named_parameters',\n",
              " 'num_parameters',\n",
              " 'parameters',\n",
              " 'pooler',\n",
              " 'prepare_inputs_for_generation',\n",
              " 'prune_heads',\n",
              " 'register_backward_hook',\n",
              " 'register_buffer',\n",
              " 'register_forward_hook',\n",
              " 'register_forward_pre_hook',\n",
              " 'register_full_backward_hook',\n",
              " 'register_load_state_dict_post_hook',\n",
              " 'register_module',\n",
              " 'register_parameter',\n",
              " 'requires_grad_',\n",
              " 'reset_memory_hooks_state',\n",
              " 'resize_token_embeddings',\n",
              " 'sample',\n",
              " 'save_pretrained',\n",
              " 'set_extra_state',\n",
              " 'set_input_embeddings',\n",
              " 'share_memory',\n",
              " 'state_dict',\n",
              " 'tie_weights',\n",
              " 'to',\n",
              " 'to_empty',\n",
              " 'train',\n",
              " 'training',\n",
              " 'type',\n",
              " 'xpu',\n",
              " 'zero_grad']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train() # dropout의 probability을 이용한다\n",
        "# 학습코드\n",
        "model.eval() # dropout의 probability을 이용한다 --> dropout 작동X\n",
        "# 평가코드"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIaKMOBfM_Wz",
        "outputId": "5974addc-7d77-46de-b6c3-e5189cf2140d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaModel(\n",
              "  (embeddings): RobertaEmbeddings(\n",
              "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "    (token_type_embeddings): Embedding(1, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): RobertaEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): RobertaPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사전학습 모델 사용해보기"
      ],
      "metadata": {
        "id": "lOjDMV-SP6wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_padding_token.shape, batch_padding_attention_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxtfJSGkND0p",
        "outputId": "89035c30-a4d6-4c30-8217-44610f735087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 58]), torch.Size([3, 58]))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_padding_token, batch_padding_attention_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0TVoHFXVZhq",
        "outputId": "4c666cfb-8a90-48ed-d26d-d336f8e20a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n",
              "            827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n",
              "              5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n",
              "            328,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n",
              "            827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n",
              "              5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n",
              "            328,     2,    83, 33130,     6,   313,     6,   122,    52,   351,\n",
              "             17,    27,    90,    28,   827, 30489,   328,     2,     1,     1,\n",
              "              1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n",
              "            827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n",
              "              5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n",
              "            328,     2,    83, 33130,     6,   313,     6,   122,    52,   351,\n",
              "             17,    27,    90,    28,   827, 30489,   328,     2,   978,     6,\n",
              "             89,    17,    27,    29,    80,  2188,     4,     2]]),\n",
              " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" for CoM \"\"\"\n",
        "batch_com_out = model(input_ids=batch_padding_token, attention_mask=batch_padding_attention_mask)['last_hidden_state']\n",
        "print(batch_com_out.shape)\n",
        "batch_com_final = batch_com_out[:,0,:] # CLS 토큰의 output 가져오기 위해\n",
        "print(batch_com_final.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGs7KoSDZs7m",
        "outputId": "29b6a4d1-d9c5-4dd3-dbb3-0c428fc223b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 58, 768])\n",
            "torch.Size([3, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_PM_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHfGhSNmVcLH",
        "outputId": "59c8a01e-e901-46f1-cdf4-de73cfcc86e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [],\n",
              " [tensor([[    0,  1185,    17,    27,   241,    10, 16333,   328,     2]])]]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model2 = RobertaModel.from_pretrained('roberta-base')\n",
        "# 발화1: feature1 [1, 768]\n",
        "# 발화3: feature3 [1, 768]\n",
        "# 발화6에 해당하는 감정을 예측할 때 발화1, 발화3의 정보를 사용할 것\n",
        "# feature1 + feature3\n",
        "# (feature1, feature6) 어텐션 weights w1\n",
        "# (feature3, feature6) 어텐션 weights w3\n",
        "# w1*feature1 + w3*feature6\n",
        "# GRU(feature1, feature3)\n",
        "\n",
        "\"\"\" GRU 세팅 \"\"\"\n",
        "import torch.nn as nn \n",
        "hiddenDim = model2.config.hidden_size\n",
        "zero = torch.empty(2, 1, hiddenDim)\n",
        "h0 = torch.zeros_like(zero) # (num_layers * num_directions, batch, hidden_size)\n",
        "speakerGRU = nn.GRU(hiddenDim, hiddenDim, 2, dropout=0.3) # (input, hidden, num_layer) (BERT_emb, BERT_emb, num_layer)\n",
        "\n",
        "\"\"\" GRU 통과 --> PM 결과 \"\"\"\n",
        "batch_pm_gru_final = []\n",
        "for PM_inputs in batch_PM_input:\n",
        "    if PM_inputs:\n",
        "        pm_outs = []\n",
        "        for PM_input in PM_inputs:\n",
        "            pm_out = model2(PM_input)['last_hidden_state'][:,0,:] # CLS의 출력\n",
        "            pm_outs.append(pm_out)\n",
        "        pm_outs = torch.cat(pm_outs, 0).unsqueeze(1) # (speaker_num, batch=1, hidden_dim)\n",
        "        pm_gru_outs, _ = speakerGRU(pm_outs, h0) # (speaker_num, batch=1, hidden_dim)\n",
        "        pm_gru_final = pm_gru_outs[-1,:,:] # (1, hidden_dim)\n",
        "        batch_pm_gru_final.append(pm_gru_final)\n",
        "    else:\n",
        "        batch_pm_gru_final.append(torch.zeros(1, hiddenDim))\n",
        "batch_pm_gru_final = torch.cat(batch_pm_gru_final, 0)"
      ],
      "metadata": {
        "id": "EMyvxdHeZi5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 추가적인 layer 구성하기"
      ],
      "metadata": {
        "id": "xO0wyqSjfKVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" score matrix \"\"\"\n",
        "clsNum = len(dev_dataset.emoList)\n",
        "W = nn.Linear(hiddenDim, clsNum)\n",
        "final_output = W(batch_com_final + batch_pm_gru_final)\n",
        "print(final_output.shape) # (B, C)|"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20bkWjmoZlyg",
        "outputId": "713121ef-9082-469b-eb55-3ea2f0ca3a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ERC_model(nn.Module):\n",
        "    def __init__(self, clsNum):\n",
        "        super(ERC_model, self).__init__()\n",
        "        self.com_model = RobertaModel.from_pretrained('roberta-base')\n",
        "        self.pm_model = RobertaModel.from_pretrained('roberta-base')\n",
        "        \n",
        "        \"\"\" GRU 세팅 \"\"\"\n",
        "        self.hiddenDim = self.com_model.config.hidden_size\n",
        "        zero = torch.empty(2, 1, self.hiddenDim)\n",
        "        self.h0 = torch.zeros_like(zero) # (num_layers * num_directions, batch, hidden_size)\n",
        "        self.speakerGRU = nn.GRU(self.hiddenDim, self.hiddenDim, 2, dropout=0.3) # (input, hidden, num_layer) (BERT_emb, BERT_emb, num_layer)\n",
        "        \n",
        "        \"\"\" score matrix \"\"\"\n",
        "        self.W = nn.Linear(self.hiddenDim, clsNum)\n",
        "    def forward(self, batch_padding_token, batch_padding_attention_mask, batch_PM_input):\n",
        "        \"\"\" for CoM \"\"\"\n",
        "        batch_com_out = self.com_model(input_ids=batch_padding_token, attention_mask=batch_padding_attention_mask)['last_hidden_state']\n",
        "        batch_com_final = batch_com_out[:,0,:]\n",
        "        \n",
        "        \"\"\" GRU 통과 --> PM 결과 \"\"\"\n",
        "        batch_pm_gru_final = []\n",
        "        for PM_inputs in batch_PM_input:\n",
        "            if PM_inputs:\n",
        "                pm_outs = []\n",
        "                for PM_input in PM_inputs:\n",
        "                    pm_out = self.pm_model(PM_input)['last_hidden_state'][:,0,:]\n",
        "                    pm_outs.append(pm_out)\n",
        "                pm_outs = torch.cat(pm_outs, 0).unsqueeze(1) # (speaker_num, batch=1, hidden_dim)\n",
        "                pm_gru_outs, _ = self.speakerGRU(pm_outs, self.h0) # (speaker_num, batch=1, hidden_dim)\n",
        "                pm_gru_final = pm_gru_outs[-1,:,:] # (1, hidden_dim)\n",
        "                batch_pm_gru_final.append(pm_gru_final)\n",
        "            else:\n",
        "                batch_pm_gru_final.append(torch.zeros(1, self.hiddenDim))\n",
        "        batch_pm_gru_final = torch.cat(batch_pm_gru_final, 0)        \n",
        "        \n",
        "        \"\"\" score matrix \"\"\"\n",
        "        final_output = self.W(batch_com_final + batch_pm_gru_final) # (B, C)\n",
        "        \n",
        "        return final_output"
      ],
      "metadata": {
        "id": "NpBllMJnegnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clsNum = len(dev_dataset.emoList)\n",
        "model = ERC_model(clsNum)\n",
        "result = model(batch_padding_token, batch_padding_attention_mask, batch_PM_input)\n",
        "print(result.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHDlZFxUfEEM",
        "outputId": "1c36a727-e367-4555-ef53-a47449c52b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 파일로 저장하기"
      ],
      "metadata": {
        "id": "hc3AvQsUhoVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!touch model.py\n"
      ],
      "metadata": {
        "id": "JLXAvuY_hj5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **학습 코드 짜기**"
      ],
      "metadata": {
        "id": "WRxLZ5JXiMuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 평가 설명하기"
      ],
      "metadata": {
        "id": "fH5_PsdYiNwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "def CalACC(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    label_list = []\n",
        "    pred_list = []\n",
        "    \n",
        "    # label arragne\n",
        "    with torch.no_grad():\n",
        "        for i_batch, data in enumerate(tqdm(dataloader)):\n",
        "            \"\"\"Prediction\"\"\"\n",
        "            batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n",
        "            batch_padding_token = batch_padding_token.cuda()\n",
        "            batch_padding_attention_mask = batch_padding_attention_mask.cuda()\n",
        "            batch_PM_input = [[x2.cuda() for x2 in x1] for x1 in batch_PM_input]\n",
        "            batch_label = batch_label.cuda()        \n",
        "\n",
        "            \"\"\"Prediction\"\"\"\n",
        "            pred_logits = erc_model(batch_padding_token, batch_padding_attention_mask, batch_PM_input)\n",
        "            \n",
        "            \"\"\"Calculation\"\"\"    \n",
        "            pred_label = pred_logits.argmax(1).item()\n",
        "            true_label = batch_label.item()\n",
        "            \n",
        "            pred_list.append(pred_label)\n",
        "            label_list.append(true_label)\n",
        "            if pred_label == true_label:\n",
        "                correct += 1\n",
        "        acc = correct/len(dataloader)\n",
        "    return acc, pred_list, label_list"
      ],
      "metadata": {
        "id": "H5FufdrPiMb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "dev_acc, dev_pred_list, dev_label_list = CalACC(erc_model, dev_dataloader)\n",
        "dev_pre, dev_rec, dev_fbeta, _ = precision_recall_fscore_support(dev_label_list, dev_pred_list, average='weighted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "qRLwwjeTNdI2",
        "outputId": "5349e6ba-a3fb-450c-b912-c58eb314c6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-af3303cf5e79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdev_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_pred_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_label_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCalACC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merc_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdev_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_fbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_label_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_pred_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'erc_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import data_loader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = data_loader('./MELD/data/MELD/train_sent_emo.csv')\n",
        "dev_dataset = data_loader('./MELD/data/MELD/dev_sent_emo.csv')\n",
        "test_dataset = data_loader('./MELD/data/MELD/test_sent_emo.csv')\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4, collate_fn=train_dataset.collate_fn)\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=1, shuffle=False, num_workers=4, collate_fn=dev_dataset.collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4, collate_fn=test_dataset.collate_fn)"
      ],
      "metadata": {
        "id": "wWSpvf9FNkjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(dev_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "VN67r2B4Nml6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model import ERC_model\n",
        "clsNum = len(train_dataset.emoList)\n",
        "erc_model = ERC_model(clsNum).cuda()"
      ],
      "metadata": {
        "id": "l22uYrHpNoNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## GPU 작동 모델 수정\n",
        "from transformers import RobertaModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ERC_model(nn.Module):\n",
        "    def __init__(self, clsNum):\n",
        "        super(ERC_model, self).__init__()\n",
        "        self.com_model = RobertaModel.from_pretrained('roberta-base')\n",
        "        self.pm_model = RobertaModel.from_pretrained('roberta-base')\n",
        "        \n",
        "        \"\"\" GRU 세팅 \"\"\"\n",
        "        self.hiddenDim = self.com_model.config.hidden_size\n",
        "        zero = torch.empty(2, 1, self.hiddenDim)\n",
        "        self.h0 = torch.zeros_like(zero).cuda() # (num_layers * num_directions, batch, hidden_size)\n",
        "        self.speakerGRU = nn.GRU(self.hiddenDim, self.hiddenDim, 2, dropout=0.3) # (input, hidden, num_layer) (BERT_emb, BERT_emb, num_layer)\n",
        "        \n",
        "        \"\"\" score matrix \"\"\"\n",
        "        self.W = nn.Linear(self.hiddenDim, clsNum)\n",
        "    def forward(self, batch_padding_token, batch_padding_attention_mask, batch_PM_input):\n",
        "        \"\"\" for CoM \"\"\"\n",
        "        batch_com_out = self.com_model(input_ids=batch_padding_token, attention_mask=batch_padding_attention_mask)['last_hidden_state']\n",
        "        batch_com_final = batch_com_out[:,0,:]\n",
        "        \n",
        "        \"\"\" GRU 통과 --> PM 결과 \"\"\"\n",
        "        batch_pm_gru_final = []\n",
        "        for PM_inputs in batch_PM_input:\n",
        "            if PM_inputs:\n",
        "                pm_outs = []\n",
        "                for PM_input in PM_inputs:\n",
        "                    pm_out = self.pm_model(PM_input)['last_hidden_state'][:,0,:]\n",
        "                    pm_outs.append(pm_out)\n",
        "                pm_outs = torch.cat(pm_outs, 0).unsqueeze(1) # (speaker_num, batch=1, hidden_dim)\n",
        "                pm_gru_outs, _ = self.speakerGRU(pm_outs, self.h0) # (speaker_num, batch=1, hidden_dim)\n",
        "                pm_gru_final = pm_gru_outs[-1,:,:] # (1, hidden_dim)\n",
        "                batch_pm_gru_final.append(pm_gru_final)\n",
        "            else:\n",
        "                batch_pm_gru_final.append(torch.zeros(1, self.hiddenDim).cuda())\n",
        "        batch_pm_gru_final = torch.cat(batch_pm_gru_final, 0)        \n",
        "        \n",
        "        \"\"\" score matrix \"\"\"\n",
        "        final_output = self.W(batch_com_final + batch_pm_gru_final) # (B, C)\n",
        "        \n",
        "        return final_output"
      ],
      "metadata": {
        "id": "43AOt7loNoqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "def CELoss(pred_outs, labels):\n",
        "    \"\"\"\n",
        "        pred_outs: [batch, clsNum]\n",
        "        labels: [batch]\n",
        "    \"\"\"\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    loss_val = loss(pred_outs, labels)\n",
        "    return loss_val"
      ],
      "metadata": {
        "id": "fStk-Zw0Nrek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "import pdb\n",
        "\n",
        "training_epochs = 5\n",
        "max_grad_norm = 10\n",
        "lr = 1e-6\n",
        "num_training_steps = len(train_dataset)*training_epochs\n",
        "num_warmup_steps = len(train_dataset)\n",
        "optimizer = torch.optim.AdamW(erc_model.parameters(), lr=lr) # , eps=1e-06, weight_decay=0.01\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n",
        "\n",
        "for epoch in tqdm(range(training_epochs)):\n",
        "    erc_model.train() \n",
        "    for i_batch, data in enumerate(train_dataloader):\n",
        "        batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n",
        "        batch_padding_token = batch_padding_token.cuda()\n",
        "        batch_padding_attention_mask = batch_padding_attention_mask.cuda()\n",
        "        batch_PM_input = [[x2.cuda() for x2 in x1] for x1 in batch_PM_input]\n",
        "        batch_label = batch_label.cuda()        \n",
        "        \n",
        "        \"\"\"Prediction\"\"\"\n",
        "        pred_logits = erc_model(batch_padding_token, batch_padding_attention_mask, batch_PM_input)\n",
        "        \n",
        "        \"\"\"Loss calculation & training\"\"\"\n",
        "        loss_val = CELoss(pred_logits, batch_label)\n",
        "        \n",
        "        loss_val.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(erc_model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()        \n",
        "        break\n",
        "    break"
      ],
      "metadata": {
        "id": "LYo-0VopNtAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 저장하기"
      ],
      "metadata": {
        "id": "wWBble3kNuVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def SaveModel(model, path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    torch.save(model.state_dict(), os.path.join(path, 'model.bin'))"
      ],
      "metadata": {
        "id": "rksClFSxNyDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "a = -(0.8*math.log(0.8)+0.2*math.log(0.2))\n",
        "b = -(0.8*math.log(0.5)+0.2*math.log(0.5))\n",
        "a, b"
      ],
      "metadata": {
        "id": "fADteb6dNzf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 최종 학습 코드"
      ],
      "metadata": {
        "id": "grI61xQ8N0X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "\n",
        "training_epochs = 5\n",
        "max_grad_norm = 10\n",
        "lr = 1e-6\n",
        "num_training_steps = len(train_dataset)*training_epochs\n",
        "num_warmup_steps = len(train_dataset)\n",
        "optimizer = torch.optim.AdamW(erc_model.parameters(), lr=lr) # , eps=1e-06, weight_decay=0.01\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n",
        "\n",
        "best_dev_fscore = 0\n",
        "save_path = '.'\n",
        "for epoch in tqdm(range(training_epochs)):\n",
        "    erc_model.train() \n",
        "    for i_batch, data in enumerate(tqdm(train_dataloader)):\n",
        "        batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n",
        "        batch_padding_token = batch_padding_token.cuda()\n",
        "        batch_padding_attention_mask = batch_padding_attention_mask.cuda()\n",
        "        batch_PM_input = [[x2.cuda() for x2 in x1] for x1 in batch_PM_input]\n",
        "        batch_label = batch_label.cuda()        \n",
        "        \n",
        "        \"\"\"Prediction\"\"\"\n",
        "        pred_logits = erc_model(batch_padding_token, batch_padding_attention_mask, batch_PM_input)\n",
        "        \n",
        "        \"\"\"Loss calculation & training\"\"\"\n",
        "        loss_val = CELoss(pred_logits, batch_label)\n",
        "        \n",
        "        loss_val.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(erc_model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "    \"\"\"Dev & Test evaluation\"\"\"\n",
        "    erc_model.eval()\n",
        "    \n",
        "    dev_acc, dev_pred_list, dev_label_list = CalACC(erc_model, dev_dataloader)\n",
        "    dev_pre, dev_rec, dev_fbeta, _ = precision_recall_fscore_support(dev_label_list, dev_pred_list, average='weighted')\n",
        "    \n",
        "    print(\"Dev W-avg F1: {}\".format(dev_fbeta))\n",
        "\n",
        "    \"\"\"Best Score & Model Save\"\"\"\n",
        "    if dev_fbeta > best_dev_fscore:\n",
        "        best_dev_fscore = dev_fbeta\n",
        "\n",
        "        test_acc, test_pred_list, test_label_list = CalACC(erc_model, test_dataloader)\n",
        "        test_pre, test_rec, test_fbeta, _ = precision_recall_fscore_support(test_label_list, test_pred_list, average='weighted')                \n",
        "\n",
        "        SaveModel(erc_model, save_path)\n",
        "        print(\"Test W-avg F1: {}\".format(test_fbeta))"
      ],
      "metadata": {
        "id": "rLtsrVcqN363"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 파일로 저장하기"
      ],
      "metadata": {
        "id": "2BzRcqsYN5wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import torch.nn as nn\n",
        "import pdb\n",
        "\n",
        "import logging\n",
        "\n",
        "# 로그 생성\n",
        "logger = logging.getLogger()\n",
        "\n",
        "# 로그의 출력 기준 설정\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# log 출력\n",
        "stream_handler = logging.StreamHandler()\n",
        "logger.addHandler(stream_handler)\n",
        "\n",
        "# log를 파일에 출력\n",
        "file_handler = logging.FileHandler('erc.log')\n",
        "logger.addHandler(file_handler)\n",
        "\n",
        "def CELoss(pred_outs, labels):\n",
        "    \"\"\"\n",
        "        pred_outs: [batch, clsNum]\n",
        "        labels: [batch]\n",
        "    \"\"\"\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    loss_val = loss(pred_outs, labels)\n",
        "    return loss_val\n",
        "\n",
        "def SaveModel(model, path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    torch.save(model.state_dict(), os.path.join(path, 'model.bin'))\n",
        "    \n",
        "def CalACC(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    label_list = []\n",
        "    pred_list = []\n",
        "    \n",
        "    # label arragne\n",
        "    with torch.no_grad():\n",
        "        for i_batch, data in enumerate(tqdm(dataloader)):\n",
        "            \"\"\"Prediction\"\"\"\n",
        "            batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n",
        "            batch_padding_token = batch_padding_token.cuda()\n",
        "            batch_padding_attention_mask = batch_padding_attention_mask.cuda()\n",
        "            batch_PM_input = [[x2.cuda() for x2 in x1] for x1 in batch_PM_input]\n",
        "            batch_label = batch_label.cuda()        \n",
        "\n",
        "            \"\"\"Prediction\"\"\"\n",
        "            pred_logits = erc_model(batch_padding_token, batch_padding_attention_mask, batch_PM_input)\n",
        "            \n",
        "            \"\"\"Calculation\"\"\"    \n",
        "            pred_label = pred_logits.argmax(1).item()\n",
        "            true_label = batch_label.item()\n",
        "            \n",
        "            pred_list.append(pred_label)\n",
        "            label_list.append(true_label)\n",
        "            if pred_label == true_label:\n",
        "                correct += 1\n",
        "        acc = correct/len(dataloader)\n",
        "    return acc, pred_list, label_list\n",
        "\n",
        "from dataset import data_loader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = data_loader('./MELD/data/MELD/train_sent_emo.csv')\n",
        "dev_dataset = data_loader('./MELD/data/MELD/dev_sent_emo.csv')\n",
        "test_dataset = data_loader('./MELD/data/MELD/test_sent_emo.csv')\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4, collate_fn=train_dataset.collate_fn)\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=1, shuffle=False, num_workers=4, collate_fn=dev_dataset.collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4, collate_fn=test_dataset.collate_fn)\n",
        "\n",
        "from model import ERC_model\n",
        "clsNum = len(train_dataset.emoList)\n",
        "erc_model = ERC_model(clsNum).cuda()\n",
        "\n",
        "\"\"\" 하이퍼 파라미터들 \"\"\"\n",
        "training_epochs = 10\n",
        "max_grad_norm = 10\n",
        "lr = 1e-6\n",
        "num_training_steps = len(train_dataset)*training_epochs\n",
        "num_warmup_steps = len(train_dataset)\n",
        "optimizer = torch.optim.AdamW(erc_model.parameters(), lr=lr) # , eps=1e-06, weight_decay=0.01\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n",
        "\n",
        "logger.info(\"############학습 시작############\")\n",
        "best_dev_fscore = 0\n",
        "save_path = '.'\n",
        "for epoch in tqdm(range(training_epochs)):\n",
        "    erc_model.train() \n",
        "    for i_batch, data in enumerate(tqdm(train_dataloader)):\n",
        "        batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n",
        "        batch_padding_token = batch_padding_token.cuda()\n",
        "        batch_padding_attention_mask = batch_padding_attention_mask.cuda()\n",
        "        batch_PM_input = [[x2.cuda() for x2 in x1] for x1 in batch_PM_input]\n",
        "        batch_label = batch_label.cuda()        \n",
        "        \n",
        "        \"\"\"Prediction\"\"\"\n",
        "        pred_logits = erc_model(batch_padding_token, batch_padding_attention_mask, batch_PM_input)\n",
        "        \n",
        "        \"\"\"Loss calculation & training\"\"\"\n",
        "        loss_val = CELoss(pred_logits, batch_label)\n",
        "        \n",
        "        loss_val.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(erc_model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "    \"\"\"Dev & Test evaluation\"\"\"\n",
        "    erc_model.eval()\n",
        "    \n",
        "    dev_acc, dev_pred_list, dev_label_list = CalACC(erc_model, dev_dataloader)\n",
        "    dev_pre, dev_rec, dev_fbeta, _ = precision_recall_fscore_support(dev_label_list, dev_pred_list, average='weighted')\n",
        "    \n",
        "    logger.info(\"Dev W-avg F1: {}\".format(dev_fbeta))\n",
        "    \n",
        "    test_acc, test_pred_list, test_label_list = CalACC(erc_model, test_dataloader)\n",
        "    \"\"\"Best Score & Model Save\"\"\"\n",
        "    if dev_fbeta > best_dev_fscore:\n",
        "        best_dev_fscore = dev_fbeta\n",
        "\n",
        "        test_acc, test_pred_list, test_label_list = CalACC(erc_model, test_dataloader)\n",
        "        test_pre, test_rec, test_fbeta, _ = precision_recall_fscore_support(test_label_list, test_pred_list, average='weighted')                \n",
        "\n",
        "        SaveModel(erc_model, save_path)\n",
        "        logger.info(\"Epoch:{}, Test W-avg F1: {}\".format(epoch, test_fbeta))"
      ],
      "metadata": {
        "id": "LG9rCqEMN8YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!touch train.py\n",
        "# 복사하기"
      ],
      "metadata": {
        "id": "Wj3pYp_PhscD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py"
      ],
      "metadata": {
        "id": "PvGCuEqKJDv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CjRKVertJKiv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}